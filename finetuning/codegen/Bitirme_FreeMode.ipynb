{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parsakzr/ytu-bitirme/blob/main/Bitirme_FreeMode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e8CK8PPwuWs",
        "outputId": "096c53d8-77b6-45b5-afae-24771a4dcad8"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate trl wandb einops\n",
        "!pip install -q -U bitsandbytes\n",
        "\n",
        "!pip -q install git+https://github.com/huggingface/peft.git\n",
        "\n",
        "# !pip install -q trl xformers wandb datasets einops sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157,
          "referenced_widgets": [
            "6fcb6805b2134250a43dcdbf0cbd6486",
            "2e23e03facd54bdc98510f7ee543df26",
            "3207d8015f274e01aef523e9c70db8d0",
            "2a0622ff09004733ab13d170c1248167",
            "a3b7395a1cb2410b944975ea46d900a3",
            "7609628f1f2142848bda6f7094685212",
            "471ced374ed44e9987b20576c62460fa",
            "eedf95f19c234b6e8e7a63f9b2723542",
            "e16025c0aafc4d94a7d88ee13fb2b4b4",
            "7b495a07645a46f68ce36d9578ec12a0",
            "5c08e2c64c1d45a486f9db8eb79655ab",
            "df4fa85a07114a93936af78c0e5439c3",
            "be41fb17c618460986e1df5974fb4b71",
            "64002d92da9f4dd2957ae2f3f96039ef",
            "909ca3e0ee1d4771ae28cfdb141fa697",
            "faa95a596bba431590d0bbb08efb3dc9",
            "3a35132fe89c49fe8d7da3048f8fba66",
            "1e3fc75dd1a040c6ac475825c2bf108b",
            "f2bd5f11c0ec4126940bddc926b53167",
            "2f34365a606341d18ac54fbb2b4a0da7",
            "b9097e2ae6bd4bc688b9def9875843e5",
            "e41f2a5b963c4618b005b6f7e6161a92",
            "ca817faae6cb435e9821b655f86fde0c",
            "ba6f1a26ff5d4591b57fcbe734363f91",
            "6feded88f8944f2395e56f5fa43d9c89",
            "5e1dd2574cea4d0b88d109b791d42495",
            "f28e100d9d19451b9752308e69baac77",
            "b77d5629434847f5ba97274938862e24",
            "7b9e3f3500a7461eaaf6e76c2aa75717",
            "20e321605e35447f892713669afa9f24",
            "1f5553ff714a4f0b9bcfbe13dd7529cf",
            "5260bc024ad940b990955b312b3e12f5"
          ]
        },
        "id": "MlenMX8xUbuy",
        "outputId": "3b6c728f-0f18-4642-a081-6ba7fba24c58"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d45e4fd867f4aafb21c5cd33b9686cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-1R1EYLs3MC"
      },
      "source": [
        "### Dataset\n",
        "The dataset is [CodeAlpaca-20k](https://github.com/sahil280114/codealpaca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "3f79310c3fe549a79a341d32e96b4d77",
            "3f0363bd22c84321928ff631e5bb60eb",
            "1777c001739b4e499140b2e41c8f7326",
            "a38b6b4d1f794559ad2b8bae18d4dc1b",
            "aa7a7037efc34962882e7c7b4753a605",
            "3338beaa611f422d81058177e54cf1f3",
            "a15fec6d2abb45059c67adcfc5435c07",
            "799408bc44ff461189ec57feea074cc4",
            "945883b4ebb34c96b767f62fa53a4928",
            "8c38bf1fe6434894854d8dc21bf0528b",
            "7cdf76b0316c461d8003edcb59fbb134",
            "e09b946c0e4d4560954259092a07e61d",
            "d31f0cffcd37445c8fd415a79c4283a7",
            "993dd6be93cc49d284fcc30c4e241cb6",
            "54a703321d654d8986550b43df7a5997",
            "d5fa2cb454ab4c2f82adeeb1ca99a955",
            "1f963c42e90c4bf9959668feb9c37d2b",
            "990631c3787340caba92062c74baf9fa",
            "ad0ca8337fbb43c1b06069f289c49ec8",
            "2be2c515b39642efb4f875b6b8ceb073",
            "97bf496c20e54e3bb729576377127d2d",
            "10792599e910436c8011577d4abb302b",
            "f96222ea0fa042aa8a124888a0a48e63",
            "0a131a63102c4e49ae1cbb4dd5b1be5b",
            "2aa759ef796245e89d167b394995e387",
            "942948f483c943c9a9b76994e502c465",
            "b260274761ec4d57b03028fea05adaec",
            "04e33707c5474f40a6be14994e75e347",
            "da72abbe38e94fafaafa7d5cf40e783a",
            "7967338d03ae4862ad539f0a60797f6c",
            "8e6cb0469e3e46bcbbf07e7e34f6c8e5",
            "86afb000da2e4435bb17290f0492af14",
            "d472a7951a524fe3bc0dfa6c6d5906ce",
            "ece7a027d59a4ed5b894e05674577f81",
            "4330c9011e874357924616af69d198e8",
            "448a8f6d94014ea8b6ea7afd2d471d1c",
            "86bcc31ed33b4b8f82fe560c79fcd762",
            "6c78f2a805904ad9baeb5aac064b74c8",
            "7906857c164e4e41858e7a43a07f183c",
            "53fcd3a11e684c00921f478c2b868870",
            "ec1d1ad2e83f465dbbf60ac9b85bc320",
            "f241370c4f8b46d68082705abebce21c",
            "11b49f0aeabb43a39c0cfd553be26e3e",
            "c6e62a87c82f4195a779e5c2f62f44da",
            "3dce127bdaa442b5b8e1201c2bc94549",
            "e8ac0329f6344d1cbaf3d4151287dd43",
            "145d5451d4bf4a3da4182a876b07462d",
            "6662cb505c554560a95087930ef18ba4",
            "b9269d2288e04b38a38069db4f17c28c",
            "9945902789f9446ebde9e5d75c5bf8d2",
            "8e096e6879b94faa90896b967cee750a",
            "68d42456c62b4d6d9c8ef71a8afda505",
            "2727337ac2894788968863b5cb854f3f",
            "3a9a319b86b846ac8c1c3ec6b0b2b808",
            "72dc9470543c4093a43eb75f6da23853"
          ]
        },
        "id": "XOj9nbg41kK5",
        "outputId": "69f24a10-5749-40ab-80e6-9d7d08df13a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['input', 'instruction', 'output'],\n",
            "    num_rows: 20022\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "dataset_id = \"sahil2801/CodeAlpaca-20k\"\n",
        "dataset = load_dataset(dataset_id, split=\"train\")\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFb1Z6hjRa9J"
      },
      "source": [
        "## Dataset preperation:\n",
        "\n",
        "\n",
        "The prompt format is as follows:\n",
        "\n",
        "```\n",
        "Below is an instruction that describes a task. Write an output that appropriately completes the request.\n",
        "### Instruction: {{instruction}}\n",
        "### Input: {{input(optional)}}\n",
        "### Output:\n",
        "<code>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RqYaD8O670Fo"
      },
      "outputs": [],
      "source": [
        "from trl import DataCollatorForCompletionOnlyLM\n",
        "# from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "# # ref: https://huggingface.co/docs/trl/main/en/sft_trainer\n",
        "# Same concept as code below but using DataCollatorForCompletionOnlyLM\n",
        "def formatting_prompts_func(example, lang='py'):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['instruction'])):\n",
        "        text = f\"Below is an instruction that describes a task. Write an output that appropriately completes the request.\\n\\n\"\n",
        "        text += f\"### Instruction: {example['instruction'][i]}\\n\\n### Input: {example['input'][i]}\\n\\n### Output:\\n\\'\\'\\'{lang}\\n{example['output'][i]}\\n\\'\\'\\'\"\n",
        "        output_texts.append(text)\n",
        "    return output_texts\n",
        "\n",
        "response_template = \"\\n### Output:\\n\"\n",
        "# completionCollator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template=response_template, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y3qtHQAU3YzR"
      },
      "outputs": [],
      "source": [
        "def prompt_function(example):\n",
        "  '''\n",
        "  alpaca (used by e.g. gpt4-x-vicuna)\n",
        "\n",
        "  ### Instruction: {{prompt}}\n",
        "  ### Input: {{input}}\n",
        "  ### Response:{{gen}}\n",
        "  '''\n",
        "\n",
        "  instruction = example['instruction']\n",
        "  inputs = example['input']\n",
        "  code = example['output']\n",
        "  lang = 'py' # TODO: make this as a column in the dataset\n",
        "  \n",
        "  prompt = f\"Below is an instruction that describes a task. Write an output that appropriately completes the request.\\n\\n\"\n",
        "  prompt += f\"### Instruction: {instruction}\\n\\n### Input: {inputs}\\n\\n### Output:\\n\\'\\'\\'{lang}\\n{code}\\n\\'\\'\\'\"\n",
        "\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XHat9zOwxiW",
        "outputId": "ed7501f6-514e-4171-b543-c9a6b7685a39"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "\n",
        "model_id = \"Salesforce/codegen-350M-mono\"\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    # device_map='auto', # 'cpu' or 'cuda'(or 'mps' for mac)\n",
        "    use_cache=False,\n",
        "    # attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "\n",
        "# Load the model, and quantize it in 4bit\n",
        "if transformers.is_bitsandbytes_available():\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "    )\n",
        "    model.config.quantization_config=bnb_config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "tokenizer.padding_side = \"right\"  # 'left' allows batched inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_response(prompt, model, tokenizer):\n",
        "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
        "  # encoded_input = encoded_input.to('mps')\n",
        "\n",
        "  generated_ids = model.generate(**encoded_input,\n",
        "                                 max_new_tokens=512,\n",
        "                                 do_sample=True,\n",
        "                                 pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "  return decoded_output[0].replace(prompt, \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try out the model on a few examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = prompt_function(dataset[4])\n",
        "print('----- Prompt -----')\n",
        "print(prompt)\n",
        "print('----- Response -----')\n",
        "print(generate_response(prompt, model, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''The output prettified:\n",
        "# Test Your Code\n",
        "\n",
        "def replace(self, *args):\n",
        "    return \"\".join([char*count for (char, count) in args for char in self])<|endoftext|>\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "f24c55fd0f08474c85ad69b2fe215359",
            "a2de351ae5254fd488bef6fd81ae0b31",
            "f4bf796dfdcf443b96c9bfe9a1784116",
            "a400557deefa4fad837cbdd4e04c9cfe",
            "a9f7178baa884ab8b9194190da5435c3",
            "bd7978e049094973b710fc0e4b769c45",
            "890650e653cf4248836deb0d3fd56d3a",
            "bad5a71507d645728c1fbd296241f43d",
            "657eb9fe4f2c4076826e00eb53c9c0c1",
            "1c13c07f0f3e4e99aa7e3511c13623e4",
            "5d8c52d64dd5419180d6053a44367777"
          ]
        },
        "id": "tnkvYs3n4MWt",
        "outputId": "750fbfa6-d494-440a-cfd1-9e4b47d765a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask'],\n",
            "    num_rows: 20022\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "def tokenize_function(example):\n",
        "  prompt = prompt_function(example)\n",
        "  # example['prompt'] = prompt\n",
        "  return tokenizer(prompt, truncation=True, return_tensors=\"pt\", add_special_tokens=True) # , padding=False,\n",
        "\n",
        "dataset_tokenized = dataset.map(tokenize_function, remove_columns=dataset.column_names) # , batched=True, num_proc=4\n",
        "print(dataset_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_tokenized = dataset_tokenized.set_format('torch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max token lenght: 1353\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data_lengths(tokenized_dataset):\n",
        "    lengths = [len(x['input_ids'][0]) for x in tokenized_dataset] # x['input_ids'][0] because return_tensors='pt', so it's a list [[**ids]]\n",
        "    print(f'Max token lenght: {max(lengths)}')\n",
        "\n",
        "    # Plotting the histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(lengths, bins=50, alpha=0.7, color='blue')\n",
        "    plt.xlabel('Length of input_ids')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Lengths of input_ids')\n",
        "    # plt.xlim([0, 800])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_data_lengths(dataset_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL4xn6xnZfPi"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorWithPadding\n",
        "# from datasets import *\n",
        "\n",
        "# Dynamic Padding; Will be used as collation_fn parameter in Dataloader\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into a training and evaluation dataset\n",
        "dataset_train_test_split = dataset_tokenized.train_test_split(test_size=0.2)\n",
        "\n",
        "# Extract the training and evaluation datasets\n",
        "dataset_train = dataset_train_test_split['train']\n",
        "dataset_eval = dataset_train_test_split['test']\n",
        "\n",
        "# print(type(_train))\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset_train, shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    dataset_eval, batch_size=8, collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew3N-_rcZW4k",
        "outputId": "38338790-194d-4fac-ccd7-30d1992f1614"
      },
      "outputs": [],
      "source": [
        "# Inspect batch health\n",
        "for batch in train_dataloader:\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_XVpLq-Siqh"
      },
      "source": [
        "## Fine-tuning ⚡⚙️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SH8BySDxlBN"
      },
      "source": [
        "### Peft config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CodeGenForCausalLM(\n",
            "  (transformer): CodeGenModel(\n",
            "    (wte): Embedding(51200, 1024)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-19): 20 x CodeGenBlock(\n",
            "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CodeGenAttention(\n",
            "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
            "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (mlp): CodeGenMLP(\n",
            "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=1024, out_features=51200, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# print model for trainable layers\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S26b-kIHwIk7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "# TODO is it necessary?\n",
        "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
        "\n",
        "#Lora config\n",
        "LORA_R = 64 # 4\n",
        "LORA_ALPHA = 16\n",
        "LORA_DROPOUT = 0.05 # similar to regularisation\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    # QLoRA paper recommended to consider ALL linear layers.\n",
        "    target_modules=[\n",
        "        \"qkv_proj\",\n",
        "        \"out_proj\",\n",
        "        \"fc_in\",\n",
        "        \"fc_out\",\n",
        "        \"lm_head\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 24313856 || all params: 381026304 || trainable%: 6.381148950808393\n"
          ]
        }
      ],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): CodeGenForCausalLM(\n",
            "      (transformer): CodeGenModel(\n",
            "        (wte): Embedding(51200, 1024)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "        (h): ModuleList(\n",
            "          (0-19): 20 x CodeGenBlock(\n",
            "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): CodeGenAttention(\n",
            "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "              (resid_dropout): Dropout(p=0.0, inplace=False)\n",
            "              (qkv_proj): lora.Linear(\n",
            "                (base_layer): Linear(in_features=1024, out_features=3072, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=1024, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (out_proj): lora.Linear(\n",
            "                (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=1024, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "            )\n",
            "            (mlp): CodeGenMLP(\n",
            "              (fc_in): lora.Linear(\n",
            "                (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=1024, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (fc_out): lora.Linear(\n",
            "                (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (act): NewGELUActivation()\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (lm_head): lora.Linear(\n",
            "        (base_layer): Linear(in_features=1024, out_features=51200, bias=True)\n",
            "        (lora_dropout): ModuleDict(\n",
            "          (default): Dropout(p=0.05, inplace=False)\n",
            "        )\n",
            "        (lora_A): ModuleDict(\n",
            "          (default): Linear(in_features=1024, out_features=64, bias=False)\n",
            "        )\n",
            "        (lora_B): ModuleDict(\n",
            "          (default): Linear(in_features=64, out_features=51200, bias=False)\n",
            "        )\n",
            "        (lora_embedding_A): ParameterDict()\n",
            "        (lora_embedding_B): ParameterDict()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trainer Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDdjToZSnFth"
      },
      "outputs": [],
      "source": [
        "## TODO: uncomment if SFTTrainer didnt work\n",
        "# from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# class CustomTrainer(Trainer):\n",
        "#     def compute_loss(self, model, inputs, return_outputs=False):\n",
        "#         # forward pass\n",
        "#         outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "#         logits = outputs.get(\"logits\")\n",
        "#         # compute custom loss (suppose one has 3 labels with different weights)\n",
        "#         loss = outputs.loss\n",
        "#         return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# The block under TrainingArguments\n",
        "\n",
        "# trainer = CustomTrainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=dataset_train,\n",
        "#     eval_dataset=dataset_eval,\n",
        "#     data_collator=data_collator,\n",
        "#     tokenizer=tokenizer,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oLxYQ30kWy0H"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "OUTPUT_DIR = 'lora-finetuned' + model_id.split(\"/\")[-1] + '-temp3'\n",
        "# OPTIM = \"paged_adamw_32bit\"\n",
        "\n",
        "''' The code below is before new training args on 2023-12-25\n",
        "# Settings for T4 (A100)\n",
        "MICRO_BATCH_SIZE = 2 # 4? for A100\n",
        "BATCH_SIZE = 128\n",
        "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE # or just 4\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 2e-4 #2e-5\n",
        "CUTOFF_LEN = 256\n",
        "\n",
        "WARMUP_RATIO = 0.03\n",
        "MAX_STEPS = 100 # 300\n",
        "MAX_GRAD_NORM = 0.3\n",
        "LR_SCHEDULER_TYPE = \"constant\"\n",
        "SAVE_STEPS = 50\n",
        "LOGGING_STEPS = 5\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    # optim=OPTIM,\n",
        "    warmup_ratio=WARMUP_RATIO, # warmup_steps=100,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
        "    # fp16=True,\n",
        "    # evaluation_strategy = \"steps\",\n",
        "    save_steps= SAVE_STEPS, # save_total_limit=3,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    report_to='tensorboard',\n",
        "    logging_steps=LOGGING_STEPS,\n",
        "    logging_dir=OUTPUT_DIR+'/logs',\n",
        "    # load_best_model_at_end=True, # requires evaluation strategy and save strategy to match\n",
        ")\n",
        "'''\n",
        "\n",
        "# MICRO_BATCH_SIZE = 2 # 4? for A100\n",
        "BATCH_SIZE = 4\n",
        "# GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE # or just 4\n",
        "MAX_STEPS = 2000 # 300\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 2e-4 #2e-5\n",
        "CUTOFF_LEN = 256\n",
        "\n",
        "WARMUP_RATIO = 0.03\n",
        "LR_SCHEDULER_TYPE = \"constant\"\n",
        "SAVE_STEPS = 100\n",
        "LOGGING_STEPS = 5\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    max_steps=MAX_STEPS,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    # optim=OPTIM,\n",
        "    warmup_ratio=WARMUP_RATIO, # warmup_steps=100,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
        "    # fp16=True,\n",
        "    # evaluation_strategy = \"steps\",\n",
        "    save_steps= SAVE_STEPS, # save_total_limit=3,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    report_to='tensorboard',\n",
        "    logging_steps=LOGGING_STEPS,\n",
        "    logging_dir=OUTPUT_DIR+'/logs',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "f9b073ae2d12425ca66c724a473bcbee",
            "980a504b495e44b185737c92176255cc",
            "532dd2779c27467bba6981ba2142090a",
            "d009c000a18b493a9697a6e4bc6b7b53",
            "6a47bd2be71043b581cdcbed3a7c4074",
            "f0373bbea3d74bbdb2402ee2da0782f8",
            "042c75088852429683fb934430736725",
            "2151d605ef2d4581ac4fa75bd48aa25f",
            "d6f4806822354ca08029a39586fa3a81",
            "706fdd531ebc47b999fe00e644e9ab19",
            "678d6d45e92a4bfc8ccf0876ef306a2e"
          ]
        },
        "id": "15r7Rk-R1DVI",
        "outputId": "db99ede4-87e4-4584-8a29-1531f69884c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/trl/trainer/utils.py:548: UserWarning: The passed formatting_func has more than one argument. Usually that function should have a single argument `example` which corresponds to the dictionary returned by each element of the dataset. Make sure you know what you are doing.\n",
            "  warnings.warn(\n",
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:267: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "MAX_SEQ_LENGTH = 512\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    # dataset_text_field=\"text\", # messy error\n",
        "    formatting_func=prompt_function, # description above, data preparation\n",
        "    # data_collator=collator,\n",
        "    packing=True,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "ftsmOy-qqSiE",
        "outputId": "e92896af-099b-4b18-b3e2-3c22109b06fb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57d7d4b358b142c18aef6951acf7fbfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.3874, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 1.1003, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 1.1256, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 0.891, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 0.8712, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
            "{'loss': 0.8799, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.757, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.9248, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.927, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.8272, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.7653, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.7208, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.7615, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.7185, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.7238, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
            "{'loss': 0.7785, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.7342, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.7351, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.7348, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.7747, 'learning_rate': 0.0002, 'epoch': 0.02}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7874, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.7827, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.6379, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.7042, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.7636, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.6931, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.7123, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.661, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.7659, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.7331, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.766, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.6923, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.7168, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.6813, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.6476, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.6684, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 0.6057, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 0.7174, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 0.7176, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 0.6826, 'learning_rate': 0.0002, 'epoch': 0.04}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7258, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 0.6282, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 0.7351, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 0.6435, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 0.7425, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
            "{'loss': 0.7853, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.6903, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.7167, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.7026, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.7058, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.6904, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.6571, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.7631, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.7322, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.6781, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.7159, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
            "{'loss': 0.7629, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
            "{'loss': 0.7118, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
            "{'loss': 0.6977, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
            "{'loss': 0.7291, 'learning_rate': 0.0002, 'epoch': 0.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7662, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
            "{'loss': 0.6489, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
            "{'loss': 0.6753, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
            "{'loss': 0.6588, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
            "{'loss': 0.6767, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
            "{'loss': 0.632, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.83, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.7051, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.7047, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.7854, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.745, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.7008, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.7291, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.6627, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.7252, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
            "{'loss': 0.6881, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 0.7127, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 0.7867, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 0.5989, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 0.7276, 'learning_rate': 0.0002, 'epoch': 0.08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7003, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 0.7453, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 0.7196, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 0.6518, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 0.6921, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 0.7462, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.7088, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.6825, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.7138, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.7274, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.7096, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.7276, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.7261, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.7223, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.749, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
            "{'loss': 0.7796, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
            "{'loss': 0.846, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
            "{'loss': 0.7323, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
            "{'loss': 0.7062, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
            "{'loss': 0.6387, 'learning_rate': 0.0002, 'epoch': 0.1}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6862, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
            "{'loss': 0.6894, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
            "{'loss': 0.6511, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
            "{'loss': 0.7058, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
            "{'loss': 0.6584, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
            "{'loss': 0.7358, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.6574, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.7604, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.7156, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.734, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.6763, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.7182, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.7652, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.7107, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.7513, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
            "{'loss': 0.6871, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
            "{'loss': 0.8397, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
            "{'loss': 0.7386, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
            "{'loss': 0.7698, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
            "{'loss': 0.7671, 'learning_rate': 0.0002, 'epoch': 0.12}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7205, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
            "{'loss': 0.7022, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
            "{'loss': 0.7008, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
            "{'loss': 0.752, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
            "{'loss': 0.6443, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
            "{'loss': 0.7708, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.7313, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.7496, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.7455, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.7501, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.6663, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.7334, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.7175, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.6836, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.762, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
            "{'loss': 0.7112, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
            "{'loss': 0.6664, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
            "{'loss': 0.6703, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
            "{'loss': 0.7307, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
            "{'loss': 0.732, 'learning_rate': 0.0002, 'epoch': 0.14}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7435, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
            "{'loss': 0.6903, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
            "{'loss': 0.7309, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
            "{'loss': 0.7275, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
            "{'loss': 0.6621, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
            "{'loss': 0.6495, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.6943, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.685, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.6602, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.794, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.7068, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.7246, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.8232, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.6725, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.7092, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
            "{'loss': 0.734, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
            "{'loss': 0.6923, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
            "{'loss': 0.7201, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
            "{'loss': 0.7569, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
            "{'loss': 0.7242, 'learning_rate': 0.0002, 'epoch': 0.16}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6728, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
            "{'loss': 0.7096, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
            "{'loss': 0.7191, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
            "{'loss': 0.6887, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
            "{'loss': 0.6964, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
            "{'loss': 0.7453, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.7536, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.7493, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.7069, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.7243, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.6468, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.6317, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.7055, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.7737, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.7014, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
            "{'loss': 0.7389, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
            "{'loss': 0.6746, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
            "{'loss': 0.7177, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
            "{'loss': 0.7137, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
            "{'loss': 0.6875, 'learning_rate': 0.0002, 'epoch': 0.18}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7174, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
            "{'loss': 0.7922, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
            "{'loss': 0.7991, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
            "{'loss': 0.7612, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
            "{'loss': 0.6466, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
            "{'loss': 0.7359, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.7626, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.7055, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.7, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.7055, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.7602, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.6543, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.7215, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.769, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.6584, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
            "{'loss': 0.7248, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
            "{'loss': 0.7368, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
            "{'loss': 0.6647, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
            "{'loss': 0.7461, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
            "{'loss': 0.7025, 'learning_rate': 0.0002, 'epoch': 0.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7045, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
            "{'loss': 0.7485, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
            "{'loss': 0.7289, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
            "{'loss': 0.6393, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
            "{'loss': 0.6819, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
            "{'loss': 0.689, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.7045, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.6866, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.6785, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.6991, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.7016, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.6589, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.6314, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.7203, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.6447, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
            "{'loss': 0.8006, 'learning_rate': 0.0002, 'epoch': 0.22}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/trl/trainer/utils.py:570: UserWarning: The dataset reached end and the iterator is reset to the start.\n",
            "  warnings.warn(\"The dataset reached end and the iterator is reset to the start.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7153, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
            "{'loss': 0.7123, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
            "{'loss': 0.7155, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
            "{'loss': 0.6364, 'learning_rate': 0.0002, 'epoch': 0.22}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7334, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
            "{'loss': 0.6719, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
            "{'loss': 0.6752, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
            "{'loss': 0.6834, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
            "{'loss': 0.7385, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
            "{'loss': 0.667, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.6381, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.6734, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.7211, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.7294, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.5857, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.6696, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.7261, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.6489, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.655, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
            "{'loss': 0.6818, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
            "{'loss': 0.6958, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
            "{'loss': 0.7173, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
            "{'loss': 0.6922, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
            "{'loss': 0.6719, 'learning_rate': 0.0002, 'epoch': 0.24}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6945, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
            "{'loss': 0.6687, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
            "{'loss': 0.6898, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
            "{'loss': 0.6549, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
            "{'loss': 0.6415, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
            "{'loss': 0.6676, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.676, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.6515, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.6312, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.6776, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.7202, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.6785, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.6441, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.6597, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.6861, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
            "{'loss': 0.6538, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
            "{'loss': 0.6235, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
            "{'loss': 0.7223, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
            "{'loss': 0.7166, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
            "{'loss': 0.6847, 'learning_rate': 0.0002, 'epoch': 0.26}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.691, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
            "{'loss': 0.6326, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
            "{'loss': 0.653, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
            "{'loss': 0.6634, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
            "{'loss': 0.6523, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
            "{'loss': 0.6806, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.7133, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.6859, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.6676, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.697, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.6409, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.7041, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.6169, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.674, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.7027, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
            "{'loss': 0.668, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
            "{'loss': 0.6382, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
            "{'loss': 0.7098, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
            "{'loss': 0.6906, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
            "{'loss': 0.6693, 'learning_rate': 0.0002, 'epoch': 0.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6409, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
            "{'loss': 0.6124, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
            "{'loss': 0.6254, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
            "{'loss': 0.5707, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
            "{'loss': 0.6356, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
            "{'loss': 0.6215, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.6473, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.6387, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.5849, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.6002, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.6673, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.6289, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.6032, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.7052, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.6634, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
            "{'loss': 0.665, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
            "{'loss': 0.6425, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
            "{'loss': 0.6337, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
            "{'loss': 0.5878, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
            "{'loss': 0.6425, 'learning_rate': 0.0002, 'epoch': 0.3}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6878, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
            "{'loss': 0.6039, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
            "{'loss': 0.7034, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
            "{'loss': 0.6482, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
            "{'loss': 0.6463, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
            "{'loss': 0.6813, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.6316, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.6154, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.6114, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.6412, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.6221, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.71, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.6106, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.6831, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.6273, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
            "{'loss': 0.6565, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
            "{'loss': 0.6103, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
            "{'loss': 0.6254, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
            "{'loss': 0.5385, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
            "{'loss': 0.7148, 'learning_rate': 0.0002, 'epoch': 0.32}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6117, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
            "{'loss': 0.7026, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
            "{'loss': 0.673, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
            "{'loss': 0.6099, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
            "{'loss': 0.5766, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
            "{'loss': 0.6318, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.6677, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.6939, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.582, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.6645, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.6922, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.6577, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.6398, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.5656, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.6315, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
            "{'loss': 0.6543, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
            "{'loss': 0.6106, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
            "{'loss': 0.6709, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
            "{'loss': 0.6655, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
            "{'loss': 0.6466, 'learning_rate': 0.0002, 'epoch': 0.34}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6291, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
            "{'loss': 0.6296, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
            "{'loss': 0.6185, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
            "{'loss': 0.6369, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
            "{'loss': 0.6031, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
            "{'loss': 0.6971, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.6216, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.6823, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.598, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.6435, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.646, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.6378, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.6317, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.5825, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.6145, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
            "{'loss': 0.6544, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
            "{'loss': 0.6574, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
            "{'loss': 0.5967, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
            "{'loss': 0.604, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
            "{'loss': 0.6441, 'learning_rate': 0.0002, 'epoch': 0.36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.685, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
            "{'loss': 0.6235, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
            "{'loss': 0.6552, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
            "{'loss': 0.6315, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
            "{'loss': 0.6721, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
            "{'loss': 0.5483, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.6638, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.6034, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.6409, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.5878, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.6597, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.6152, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.568, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.6592, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.6725, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
            "{'loss': 0.6421, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
            "{'loss': 0.712, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
            "{'loss': 0.6408, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
            "{'loss': 0.668, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
            "{'loss': 0.7136, 'learning_rate': 0.0002, 'epoch': 0.38}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7095, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
            "{'loss': 0.5991, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
            "{'loss': 0.7207, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
            "{'loss': 0.6739, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
            "{'loss': 0.6032, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
            "{'loss': 0.6152, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.6108, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.7451, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.6966, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.5852, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.6683, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.7453, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.6663, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.6624, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.7484, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
            "{'loss': 0.6306, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
            "{'loss': 0.6272, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
            "{'loss': 0.6517, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
            "{'loss': 0.6212, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
            "{'loss': 0.604, 'learning_rate': 0.0002, 'epoch': 0.4}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 52295.1865, 'train_samples_per_second': 0.153, 'train_steps_per_second': 0.038, 'train_loss': 0.6930881524085999, 'epoch': 0.4}\n"
          ]
        }
      ],
      "source": [
        "trainer.train()\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CagQzIhjTHdz"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBuIbALJZqsq",
        "outputId": "805b919a-a8bc-4416-81d0-652892816811"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qfz1UCsYWZE",
        "outputId": "14fbc189-69e7-4301-d0c8-e5937a050ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded Salesforce/codegen-350M-mono with lora-finetunedcodegen-350M-mono-temp3 adaptors\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# model_id = \"Salesforce/codegen-350M-mono\"\n",
        "# OUTPUT_DIR = 'lora-finetuned' + model_id.split(\"/\")[-1]\n",
        "# adapters_id = 'lora-finetunedcodegen-350M-mono-temp2'\n",
        "adapters_id = OUTPUT_DIR\n",
        "print(f\"loaded {model_id} with {adapters_id} adaptors\")\n",
        "\n",
        "# Load the model, and quantize it in 4bit\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.float16,\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    # device_map='mps',\n",
        "    # quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "model.config.use_cache=False\n",
        "\n",
        "# Load my peft config\n",
        "model = PeftModel.from_pretrained(model, adapters_id)\n",
        "model = model.merge_and_unload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-SpOmHVaQMo",
        "outputId": "9dcbdd27-ef34-4c5a-95a8-cb077a7d7873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def hash_function(string):\n",
            "    return hash(string)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_pipeline(text, verbose=False, pure_mode=True):\n",
        "    def generate_prompt(text):\n",
        "      prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\"\n",
        "      prompt += f\"### Instruction: {text}\\n\\n### Output:\\n\"\n",
        "      return prompt\n",
        "\n",
        "    prompt = generate_prompt(text)\n",
        "    if(verbose):\n",
        "      print(f'------------ Prompt -------------\\n{prompt}')\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
        "    # input_ids = input_ids.to('mps')\n",
        "    generated_ids = model.generate(input_ids, \n",
        "                                  max_new_tokens=256, # TODO: this or max_length?\n",
        "                                  pad_token_id=tokenizer.eos_token_id,\n",
        "                                  # no_repeat_ngram_size=1,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=2,\n",
        "                                  # temperature=0.1,\n",
        "                                  # do_sample=True,\n",
        "                                  )\n",
        "\n",
        "    output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "    if(pure_mode):\n",
        "      # remove the prompt, since it's a completion model\n",
        "      output = output.replace(prompt, \"\")\n",
        "      # select the text between the two '''\n",
        "      output = output.split('\\'\\'\\'')[1]\n",
        "      # remove the first line (which is the language)\n",
        "      output = '\\n'.join(output.split('\\n')[1:])\n",
        "    if(verbose):\n",
        "      print(f'-------- Generated Output --------\\n{output}')\n",
        "\n",
        "    return output\n",
        "\n",
        "output = generate_pipeline(\"Create a function that implements a hashing function.\",\n",
        "                            verbose=False)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Prompt -------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction: Write a Python function 'has_close_elements(numbers: List[float], threshhold: float) -> bool' to solve the following problem:\n",
            "def has_close_elements(numbers: List[float], threshhold: float) -> bool:\n",
            "\"\"\"Check if in given list of numbers, are any two numbers closer to each other than given threshold.\n",
            " >>> has_close_elements([1.0, 2.0, 3.0], 0.5) False\n",
            " >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0], 0.3) True\"\"\"\n",
            "\n",
            "\n",
            "### Output:\n",
            "\n",
            "-------- Generated Output --------\n",
            "def has_close_elements(numbers: List[float], threshhold: float) -> bool:\n",
            "    \"\"\"Check if in given list of numbers, are any two numbers closer to each other than given threshold.\n",
            "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5) False\n",
            "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0], 0.3) True\n",
            "    \"\"\"\n",
            "    for i in range(len(numbers) - 1):\n",
            "        for j in range(i + 1, len(numbers)):\n",
            "            if abs(numbers[i] - numbers[j]) > threshhold:\n",
            "                return False\n",
            "    return True\n",
            "\n",
            "def has_close_elements(numbers: List[float], threshhold: float) -> bool:\n",
            "    \"\"\"Check if in given list of numbers, are any two numbers closer to each other than given threshold.\n",
            "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5) False\n",
            "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0], 0.3) True\n",
            "    \"\"\"\n",
            "    for i in range(len(numbers) - 1):\n",
            "        for j in range(i + 1, len(numbers)):\n",
            "            if abs(numbers[i] - numbers[j]) > threshhold:\n",
            "                return False\n",
            "    return True\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# print(generate_pipeline(\"Please complete the following Python code without providing any additional tasks such as testing or explanations.\\nCreate a function to find the maximum value between two given inputs.\"))\n",
        "print(generate_pipeline(\"Write a Python function \\'has_close_elements(numbers: List[float], threshhold: float) -> bool\\' to solve the following problem:\\ndef has_close_elements(numbers: List[float], threshhold: float) -> bool:\\n\\\"\\\"\\\"Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n >>> has_close_elements([1.0, 2.0, 3.0], 0.5) False\\n >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0], 0.3) True\\\"\\\"\\\"\\n\"\n",
        "                        , verbose=True, pure_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/parsak/codegen-350M-mono-lora-instruction/commit/9a3046b87b80bdbc19fa8cb3e14764de3841b986', commit_message='Upload tokenizer', commit_description='', oid='9a3046b87b80bdbc19fa8cb3e14764de3841b986', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Push to HuggingFace Hub\n",
        "\n",
        "model.push_to_hub('parsak/codegen-350M-mono-lora-instruction')\n",
        "tokenizer.push_to_hub('parsak/codegen-350M-mono-lora-instruction')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfFQMxAuJ2SL"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLW8b2SGKzja",
        "outputId": "112905b5-d658-4026-cb65-e3a68bd22155"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/openai/human-eval.git\n",
        "!pip install -e human-eval\n",
        "\n",
        "  # build             build everything needed to install\n",
        "  # build_py          \"build\" pure Python modules (copy to build directory)\n",
        "  # build_ext         build C/C++ extensions (compile/link to build directory)\n",
        "  # build_clib        build C/C++ libraries used by Python extensions\n",
        "  # build_scripts     \"build\" scripts (copy and fixup #! line)\n",
        "  # clean             clean up temporary files from 'build' command\n",
        "  # install           install everything from build directory\n",
        "  # install_lib       install all Python modules (extensions and pure Python)\n",
        "  # install_headers   install C/C++ header files\n",
        "  # install_scripts   install scripts (Python or otherwise)\n",
        "  # install_data      install data files\n",
        "  # sdist             create a source distribution (tarball, zip file, etc.)\n",
        "  # register          register the distribution with the Python package index\n",
        "  # bdist             create a built (binary) distribution\n",
        "  # bdist_dumb        create a \"dumb\" built distribution\n",
        "  # bdist_rpm         create an RPM distribution\n",
        "  # check             perform some checks on the package\n",
        "  # upload            upload binary package to PyPI\n",
        "%cd human-eval\n",
        "!pwd\n",
        "!python setup.py install\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3BpUxn9J0ph",
        "outputId": "41243902-aa1e-43f9-8f98-27483deb9c2f"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[48], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task_id \u001b[38;5;129;01min\u001b[39;00m problems:\n\u001b[1;32m     19\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples_per_task):\n\u001b[0;32m---> 20\u001b[0m     samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mdict\u001b[39m(task_id\u001b[38;5;241m=\u001b[39mtask_id, completion\u001b[38;5;241m=\u001b[39m\u001b[43mgenerate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblems\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     21\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msamples[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(samples)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_total\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[36], line 13\u001b[0m, in \u001b[0;36mgenerate_pipeline\u001b[0;34m(text, verbose, pure_mode)\u001b[0m\n\u001b[1;32m     11\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# input_ids = input_ids.to('mps')\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# TODO: this or max_length?\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;66;43;03m# no_repeat_ngram_size=1,\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;66;43;03m# temperature=0.1,\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;66;43;03m# do_sample=True,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(pure_mode):\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;66;03m# remove the prompt, since it's a completion model\u001b[39;00m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/transformers/generation/utils.py:1797\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1790\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1791\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1792\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1793\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1795\u001b[0m     )\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[0;32m-> 1797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE:\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/transformers/generation/utils.py:3181\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3177\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3179\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 3181\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3184\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3185\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3189\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/transformers/models/codegen/modeling_codegen.py:675\u001b[0m, in \u001b[0;36mCodeGenForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    673\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 675\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# make sure sampling in fp16 works correctly and\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;66;03m# compute loss in fp32 to match with mesh-tf version\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# https://github.com/EleutherAI/gpt-neo/blob/89ce74164da2fb16179106f54e2269b5da8db333/models/gpt2/gpt2.py#L179\u001b[39;00m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/transformers/models/codegen/modeling_codegen.py:552\u001b[0m, in \u001b[0;36mCodeGenModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    541\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    542\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    543\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    549\u001b[0m         output_attentions,\n\u001b[1;32m    550\u001b[0m     )\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/transformers/models/codegen/modeling_codegen.py:288\u001b[0m, in \u001b[0;36mCodeGenBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    286\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    287\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 288\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    298\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/transformers/models/codegen/modeling_codegen.py:234\u001b[0m, in \u001b[0;36mCodeGenAttention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    231\u001b[0m     present \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# compute self-attention: V x Softmax(QK^T)\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_heads(attn_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    237\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj(attn_output)\n",
            "File \u001b[0;32m~/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/transformers/models/codegen/modeling_codegen.py:163\u001b[0m, in \u001b[0;36mCodeGenAttention._attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[0;32m--> 163\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from human_eval.data import write_jsonl, read_problems\n",
        "from tqdm import tqdm\n",
        "# generate_pipeline already handled\n",
        "\n",
        "#retrieve all the humanEval questions\n",
        "problems = read_problems()\n",
        "num_samples_per_task = 1 #200 pass@1 pass@10 ...\n",
        "# samples = [\n",
        "#     dict(task_id=task_id, completion=generate_pipeline(problems[task_id][\"prompt\"], verbose=True))\n",
        "#     for task_id in problems\n",
        "#     for _ in range(num_samples_per_task)\n",
        "# ]\n",
        "\n",
        "samples = []\n",
        "# tqdm for the progress bar\n",
        "tqdm.write(f\"Generating {num_samples_per_task} samples per task for {len(problems)} tasks\")\n",
        "num_total = len(problems) * num_samples_per_task\n",
        "for task_id in problems:\n",
        "  for _ in range(num_samples_per_task):\n",
        "    samples.append(dict(task_id=task_id, completion=generate_pipeline(problems[task_id][\"prompt\"])))\n",
        "    tqdm.write(f\"Task {task_id}: {samples[-1]['completion']}\")\n",
        "    tqdm.write(f\"{len(samples)}/{num_total}\")\n",
        "\n",
        "    tqdm.display()\n",
        "\n",
        "\n",
        "#outputs task_id, completion pairs\n",
        "write_jsonl(\"samples.jsonl\", samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvVJmIELKs4d",
        "outputId": "b4a9fd01-0995-470d-e4e9-b6e1f46cbe9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading samples...\n",
            "164it [00:00, 66236.48it/s]\n",
            "Running test suites...\n",
            "  0%|                                                   | 0/164 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/bin/evaluate_functional_correctness\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('human-eval==1.0', 'console_scripts', 'evaluate_functional_correctness')())\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/bin/evaluate_functional_correctness\", line 25, in importlib_load_entry_point\n",
            "    return next(matches).load()\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/importlib/metadata/__init__.py\", line 171, in load\n",
            "    module = import_module(match.group('module'))\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/evaluate_functional_correctness.py\", line 28, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/evaluate_functional_correctness.py\", line 25, in main\n",
            "    fire.Fire(entry_point)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/fire-0.5.0-py3.10.egg/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/fire-0.5.0-py3.10.egg/fire/core.py\", line 475, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/fire-0.5.0-py3.10.egg/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/evaluate_functional_correctness.py\", line 20, in entry_point\n",
            "    results = evaluate_functional_correctness(sample_file, k, n_workers, timeout, problem_file)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/evaluation.py\", line 75, in evaluate_functional_correctness\n",
            "    result = future.result()\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/execution.py\", line 77, in check_correctness\n",
            "    p.start()\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 121, in start\n",
            "    self._popen = self._Popen(self)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n",
            "    return _default_context.get_context().Process._Popen(process_obj)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/context.py\", line 288, in _Popen\n",
            "    return Popen(process_obj)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\n",
            "    super().__init__(process_obj)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n",
            "    self._launch(process_obj)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/popen_spawn_posix.py\", line 47, in _launch\n",
            "    reduction.dump(process_obj, fp)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/reduction.py\", line 60, in dump\n",
            "    ForkingPickler(file, protocol).dump(obj)\n",
            "AttributeError: Can't pickle local object 'check_correctness.<locals>.unsafe_execute'\n"
          ]
        }
      ],
      "source": [
        "!evaluate_functional_correctness humaneval_Salesforce_codegen-350M-mono_predictions.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWnQs7xdgfj4",
        "outputId": "b61b067e-db52-41d3-b97c-ed244c5df6cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading samples...\n",
            "6it [00:00, 9144.56it/s]\n",
            "Running test suites...\n",
            "  0%|                                                     | 0/6 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/bin/evaluate_functional_correctness\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('human-eval==1.0', 'console_scripts', 'evaluate_functional_correctness')())\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/bin/evaluate_functional_correctness\", line 25, in importlib_load_entry_point\n",
            "    return next(matches).load()\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/importlib/metadata/__init__.py\", line 171, in load\n",
            "    module = import_module(match.group('module'))\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/evaluate_functional_correctness.py\", line 28, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/evaluate_functional_correctness.py\", line 25, in main\n",
            "    fire.Fire(entry_point)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/fire-0.5.0-py3.10.egg/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/fire-0.5.0-py3.10.egg/fire/core.py\", line 475, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/fire-0.5.0-py3.10.egg/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/evaluate_functional_correctness.py\", line 20, in entry_point\n",
            "    results = evaluate_functional_correctness(sample_file, k, n_workers, timeout, problem_file)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/evaluation.py\", line 75, in evaluate_functional_correctness\n",
            "    result = future.result()\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/human_eval-1.0-py3.10.egg/human_eval/execution.py\", line 77, in check_correctness\n",
            "    p.start()\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 121, in start\n",
            "    self._popen = self._Popen(self)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n",
            "    return _default_context.get_context().Process._Popen(process_obj)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/context.py\", line 288, in _Popen\n",
            "    return Popen(process_obj)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\n",
            "    super().__init__(process_obj)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n",
            "    self._launch(process_obj)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/popen_spawn_posix.py\", line 47, in _launch\n",
            "    reduction.dump(process_obj, fp)\n",
            "  File \"/Users/parsa/lib/miniconda3/envs/torch-gpu/lib/python3.10/multiprocessing/reduction.py\", line 60, in dump\n",
            "    ForkingPickler(file, protocol).dump(obj)\n",
            "AttributeError: Can't pickle local object 'check_correctness.<locals>.unsafe_execute'\n"
          ]
        }
      ],
      "source": [
        "!evaluate_functional_correctness human-eval/data/example_samples.jsonl --problem_file=human-eval/data/example_problem.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHq8UImjhCAo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DfFQMxAuJ2SL"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "042c75088852429683fb934430736725": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04e33707c5474f40a6be14994e75e347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a131a63102c4e49ae1cbb4dd5b1be5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e33707c5474f40a6be14994e75e347",
            "placeholder": "​",
            "style": "IPY_MODEL_da72abbe38e94fafaafa7d5cf40e783a",
            "value": "Downloading data: 100%"
          }
        },
        "10792599e910436c8011577d4abb302b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11b49f0aeabb43a39c0cfd553be26e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "145d5451d4bf4a3da4182a876b07462d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d42456c62b4d6d9c8ef71a8afda505",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2727337ac2894788968863b5cb854f3f",
            "value": 1
          }
        },
        "1777c001739b4e499140b2e41c8f7326": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_799408bc44ff461189ec57feea074cc4",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_945883b4ebb34c96b767f62fa53a4928",
            "value": 147
          }
        },
        "1c13c07f0f3e4e99aa7e3511c13623e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3fc75dd1a040c6ac475825c2bf108b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2bd5f11c0ec4126940bddc926b53167",
            "placeholder": "​",
            "style": "IPY_MODEL_2f34365a606341d18ac54fbb2b4a0da7",
            "value": "Connecting..."
          }
        },
        "1f5553ff714a4f0b9bcfbe13dd7529cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f963c42e90c4bf9959668feb9c37d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e321605e35447f892713669afa9f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2151d605ef2d4581ac4fa75bd48aa25f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2727337ac2894788968863b5cb854f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a0622ff09004733ab13d170c1248167": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_df4fa85a07114a93936af78c0e5439c3",
            "style": "IPY_MODEL_be41fb17c618460986e1df5974fb4b71",
            "value": true
          }
        },
        "2aa759ef796245e89d167b394995e387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7967338d03ae4862ad539f0a60797f6c",
            "max": 8057896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e6cb0469e3e46bcbbf07e7e34f6c8e5",
            "value": 8057896
          }
        },
        "2be2c515b39642efb4f875b6b8ceb073": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e23e03facd54bdc98510f7ee543df26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eedf95f19c234b6e8e7a63f9b2723542",
            "placeholder": "​",
            "style": "IPY_MODEL_e16025c0aafc4d94a7d88ee13fb2b4b4",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "2f34365a606341d18ac54fbb2b4a0da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3207d8015f274e01aef523e9c70db8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7b495a07645a46f68ce36d9578ec12a0",
            "placeholder": "​",
            "style": "IPY_MODEL_5c08e2c64c1d45a486f9db8eb79655ab",
            "value": ""
          }
        },
        "3338beaa611f422d81058177e54cf1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a35132fe89c49fe8d7da3048f8fba66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a9a319b86b846ac8c1c3ec6b0b2b808": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dce127bdaa442b5b8e1201c2bc94549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8ac0329f6344d1cbaf3d4151287dd43",
              "IPY_MODEL_145d5451d4bf4a3da4182a876b07462d",
              "IPY_MODEL_6662cb505c554560a95087930ef18ba4"
            ],
            "layout": "IPY_MODEL_b9269d2288e04b38a38069db4f17c28c"
          }
        },
        "3f0363bd22c84321928ff631e5bb60eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3338beaa611f422d81058177e54cf1f3",
            "placeholder": "​",
            "style": "IPY_MODEL_a15fec6d2abb45059c67adcfc5435c07",
            "value": "Downloading readme: 100%"
          }
        },
        "3f79310c3fe549a79a341d32e96b4d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f0363bd22c84321928ff631e5bb60eb",
              "IPY_MODEL_1777c001739b4e499140b2e41c8f7326",
              "IPY_MODEL_a38b6b4d1f794559ad2b8bae18d4dc1b"
            ],
            "layout": "IPY_MODEL_aa7a7037efc34962882e7c7b4753a605"
          }
        },
        "4330c9011e874357924616af69d198e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7906857c164e4e41858e7a43a07f183c",
            "placeholder": "​",
            "style": "IPY_MODEL_53fcd3a11e684c00921f478c2b868870",
            "value": "Extracting data files: 100%"
          }
        },
        "448a8f6d94014ea8b6ea7afd2d471d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec1d1ad2e83f465dbbf60ac9b85bc320",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f241370c4f8b46d68082705abebce21c",
            "value": 1
          }
        },
        "471ced374ed44e9987b20576c62460fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "5260bc024ad940b990955b312b3e12f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "532dd2779c27467bba6981ba2142090a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2151d605ef2d4581ac4fa75bd48aa25f",
            "max": 20022,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6f4806822354ca08029a39586fa3a81",
            "value": 20022
          }
        },
        "53fcd3a11e684c00921f478c2b868870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54a703321d654d8986550b43df7a5997": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97bf496c20e54e3bb729576377127d2d",
            "placeholder": "​",
            "style": "IPY_MODEL_10792599e910436c8011577d4abb302b",
            "value": " 1/1 [00:00&lt;00:00,  1.74it/s]"
          }
        },
        "5c08e2c64c1d45a486f9db8eb79655ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d8c52d64dd5419180d6053a44367777": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e1dd2574cea4d0b88d109b791d42495": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64002d92da9f4dd2957ae2f3f96039ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657eb9fe4f2c4076826e00eb53c9c0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6662cb505c554560a95087930ef18ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a9a319b86b846ac8c1c3ec6b0b2b808",
            "placeholder": "​",
            "style": "IPY_MODEL_72dc9470543c4093a43eb75f6da23853",
            "value": " 20022/0 [00:00&lt;00:00, 48553.94 examples/s]"
          }
        },
        "678d6d45e92a4bfc8ccf0876ef306a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68d42456c62b4d6d9c8ef71a8afda505": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6a47bd2be71043b581cdcbed3a7c4074": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c78f2a805904ad9baeb5aac064b74c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fcb6805b2134250a43dcdbf0cbd6486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9097e2ae6bd4bc688b9def9875843e5",
              "IPY_MODEL_e41f2a5b963c4618b005b6f7e6161a92",
              "IPY_MODEL_ca817faae6cb435e9821b655f86fde0c",
              "IPY_MODEL_ba6f1a26ff5d4591b57fcbe734363f91"
            ],
            "layout": "IPY_MODEL_471ced374ed44e9987b20576c62460fa"
          }
        },
        "6feded88f8944f2395e56f5fa43d9c89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "706fdd531ebc47b999fe00e644e9ab19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72dc9470543c4093a43eb75f6da23853": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7609628f1f2142848bda6f7094685212": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa95a596bba431590d0bbb08efb3dc9",
            "placeholder": "​",
            "style": "IPY_MODEL_3a35132fe89c49fe8d7da3048f8fba66",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7906857c164e4e41858e7a43a07f183c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7967338d03ae4862ad539f0a60797f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "799408bc44ff461189ec57feea074cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b495a07645a46f68ce36d9578ec12a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9e3f3500a7461eaaf6e76c2aa75717": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cdf76b0316c461d8003edcb59fbb134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86afb000da2e4435bb17290f0492af14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bcc31ed33b4b8f82fe560c79fcd762": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11b49f0aeabb43a39c0cfd553be26e3e",
            "placeholder": "​",
            "style": "IPY_MODEL_c6e62a87c82f4195a779e5c2f62f44da",
            "value": " 1/1 [00:00&lt;00:00, 29.85it/s]"
          }
        },
        "890650e653cf4248836deb0d3fd56d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c38bf1fe6434894854d8dc21bf0528b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e096e6879b94faa90896b967cee750a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e6cb0469e3e46bcbbf07e7e34f6c8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "909ca3e0ee1d4771ae28cfdb141fa697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "942948f483c943c9a9b76994e502c465": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86afb000da2e4435bb17290f0492af14",
            "placeholder": "​",
            "style": "IPY_MODEL_d472a7951a524fe3bc0dfa6c6d5906ce",
            "value": " 8.06M/8.06M [00:00&lt;00:00, 8.81MB/s]"
          }
        },
        "945883b4ebb34c96b767f62fa53a4928": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97bf496c20e54e3bb729576377127d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980a504b495e44b185737c92176255cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0373bbea3d74bbdb2402ee2da0782f8",
            "placeholder": "​",
            "style": "IPY_MODEL_042c75088852429683fb934430736725",
            "value": "Map: 100%"
          }
        },
        "990631c3787340caba92062c74baf9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "993dd6be93cc49d284fcc30c4e241cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad0ca8337fbb43c1b06069f289c49ec8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2be2c515b39642efb4f875b6b8ceb073",
            "value": 1
          }
        },
        "9945902789f9446ebde9e5d75c5bf8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a15fec6d2abb45059c67adcfc5435c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2de351ae5254fd488bef6fd81ae0b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd7978e049094973b710fc0e4b769c45",
            "placeholder": "​",
            "style": "IPY_MODEL_890650e653cf4248836deb0d3fd56d3a",
            "value": "Map: 100%"
          }
        },
        "a38b6b4d1f794559ad2b8bae18d4dc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c38bf1fe6434894854d8dc21bf0528b",
            "placeholder": "​",
            "style": "IPY_MODEL_7cdf76b0316c461d8003edcb59fbb134",
            "value": " 147/147 [00:00&lt;00:00, 4.74kB/s]"
          }
        },
        "a3b7395a1cb2410b944975ea46d900a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_64002d92da9f4dd2957ae2f3f96039ef",
            "style": "IPY_MODEL_909ca3e0ee1d4771ae28cfdb141fa697",
            "tooltip": ""
          }
        },
        "a400557deefa4fad837cbdd4e04c9cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c13c07f0f3e4e99aa7e3511c13623e4",
            "placeholder": "​",
            "style": "IPY_MODEL_5d8c52d64dd5419180d6053a44367777",
            "value": " 20022/20022 [00:05&lt;00:00, 3925.25 examples/s]"
          }
        },
        "a9f7178baa884ab8b9194190da5435c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa7a7037efc34962882e7c7b4753a605": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad0ca8337fbb43c1b06069f289c49ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b260274761ec4d57b03028fea05adaec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77d5629434847f5ba97274938862e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9097e2ae6bd4bc688b9def9875843e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6feded88f8944f2395e56f5fa43d9c89",
            "placeholder": "​",
            "style": "IPY_MODEL_5e1dd2574cea4d0b88d109b791d42495",
            "value": "Token is valid (permission: write)."
          }
        },
        "b9269d2288e04b38a38069db4f17c28c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6f1a26ff5d4591b57fcbe734363f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5553ff714a4f0b9bcfbe13dd7529cf",
            "placeholder": "​",
            "style": "IPY_MODEL_5260bc024ad940b990955b312b3e12f5",
            "value": "Login successful"
          }
        },
        "bad5a71507d645728c1fbd296241f43d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd7978e049094973b710fc0e4b769c45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be41fb17c618460986e1df5974fb4b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6e62a87c82f4195a779e5c2f62f44da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca817faae6cb435e9821b655f86fde0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9e3f3500a7461eaaf6e76c2aa75717",
            "placeholder": "​",
            "style": "IPY_MODEL_20e321605e35447f892713669afa9f24",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "d009c000a18b493a9697a6e4bc6b7b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_706fdd531ebc47b999fe00e644e9ab19",
            "placeholder": "​",
            "style": "IPY_MODEL_678d6d45e92a4bfc8ccf0876ef306a2e",
            "value": " 20022/20022 [00:07&lt;00:00, 3458.42 examples/s]"
          }
        },
        "d31f0cffcd37445c8fd415a79c4283a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f963c42e90c4bf9959668feb9c37d2b",
            "placeholder": "​",
            "style": "IPY_MODEL_990631c3787340caba92062c74baf9fa",
            "value": "Downloading data files: 100%"
          }
        },
        "d472a7951a524fe3bc0dfa6c6d5906ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5fa2cb454ab4c2f82adeeb1ca99a955": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f4806822354ca08029a39586fa3a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da72abbe38e94fafaafa7d5cf40e783a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df4fa85a07114a93936af78c0e5439c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09b946c0e4d4560954259092a07e61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d31f0cffcd37445c8fd415a79c4283a7",
              "IPY_MODEL_993dd6be93cc49d284fcc30c4e241cb6",
              "IPY_MODEL_54a703321d654d8986550b43df7a5997"
            ],
            "layout": "IPY_MODEL_d5fa2cb454ab4c2f82adeeb1ca99a955"
          }
        },
        "e16025c0aafc4d94a7d88ee13fb2b4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e41f2a5b963c4618b005b6f7e6161a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28e100d9d19451b9752308e69baac77",
            "placeholder": "​",
            "style": "IPY_MODEL_b77d5629434847f5ba97274938862e24",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "e8ac0329f6344d1cbaf3d4151287dd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9945902789f9446ebde9e5d75c5bf8d2",
            "placeholder": "​",
            "style": "IPY_MODEL_8e096e6879b94faa90896b967cee750a",
            "value": "Generating train split: "
          }
        },
        "ec1d1ad2e83f465dbbf60ac9b85bc320": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece7a027d59a4ed5b894e05674577f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4330c9011e874357924616af69d198e8",
              "IPY_MODEL_448a8f6d94014ea8b6ea7afd2d471d1c",
              "IPY_MODEL_86bcc31ed33b4b8f82fe560c79fcd762"
            ],
            "layout": "IPY_MODEL_6c78f2a805904ad9baeb5aac064b74c8"
          }
        },
        "eedf95f19c234b6e8e7a63f9b2723542": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0373bbea3d74bbdb2402ee2da0782f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f241370c4f8b46d68082705abebce21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f24c55fd0f08474c85ad69b2fe215359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2de351ae5254fd488bef6fd81ae0b31",
              "IPY_MODEL_f4bf796dfdcf443b96c9bfe9a1784116",
              "IPY_MODEL_a400557deefa4fad837cbdd4e04c9cfe"
            ],
            "layout": "IPY_MODEL_a9f7178baa884ab8b9194190da5435c3"
          }
        },
        "f28e100d9d19451b9752308e69baac77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2bd5f11c0ec4126940bddc926b53167": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4bf796dfdcf443b96c9bfe9a1784116": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad5a71507d645728c1fbd296241f43d",
            "max": 20022,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_657eb9fe4f2c4076826e00eb53c9c0c1",
            "value": 20022
          }
        },
        "f96222ea0fa042aa8a124888a0a48e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a131a63102c4e49ae1cbb4dd5b1be5b",
              "IPY_MODEL_2aa759ef796245e89d167b394995e387",
              "IPY_MODEL_942948f483c943c9a9b76994e502c465"
            ],
            "layout": "IPY_MODEL_b260274761ec4d57b03028fea05adaec"
          }
        },
        "f9b073ae2d12425ca66c724a473bcbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_980a504b495e44b185737c92176255cc",
              "IPY_MODEL_532dd2779c27467bba6981ba2142090a",
              "IPY_MODEL_d009c000a18b493a9697a6e4bc6b7b53"
            ],
            "layout": "IPY_MODEL_6a47bd2be71043b581cdcbed3a7c4074"
          }
        },
        "faa95a596bba431590d0bbb08efb3dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
