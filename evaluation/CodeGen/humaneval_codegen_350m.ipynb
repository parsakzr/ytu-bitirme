{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHpm7BDINjqEzImgj0Lqjv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parsakzr/ytu-bitirme/blob/main/HumanEvalOnColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPUCdkbG-Nq0",
        "outputId": "4e5e1590-b20b-42ea-c4e4-1964b5d619d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'human-eval'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 29 (delta 8), reused 4 (delta 4), pack-reused 9\u001b[K\n",
            "Receiving objects: 100% (29/29), 54.20 KiB | 2.08 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "Obtaining file:///content/human-eval\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from human-eval==1.0) (4.66.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from human-eval==1.0) (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from human-eval==1.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->human-eval==1.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->human-eval==1.0) (2.4.0)\n",
            "Installing collected packages: human-eval\n",
            "  Running setup.py develop for human-eval\n",
            "Successfully installed human-eval-1.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/openai/human-eval\n",
        "!pip install -e human-eval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf human-eval/"
      ],
      "metadata": {
        "id": "6dldpaoIA1hp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/human-eval/human_eval/execution.py\n",
        "from typing import Optional, Callable, Dict\n",
        "import ast\n",
        "import contextlib\n",
        "import faulthandler\n",
        "import io\n",
        "import os\n",
        "import multiprocessing\n",
        "import platform\n",
        "import signal\n",
        "import tempfile\n",
        "\n",
        "\n",
        "def check_correctness(problem: Dict, completion: str, timeout: float,\n",
        "                      completion_id: Optional[int] = None) -> Dict:\n",
        "    \"\"\"\n",
        "    Evaluates the functional correctness of a completion by running the test\n",
        "    suite provided in the problem.\n",
        "\n",
        "    :param completion_id: an optional completion ID so we can match\n",
        "        the results later even if execution finishes asynchronously.\n",
        "    \"\"\"\n",
        "\n",
        "    def unsafe_execute():\n",
        "\n",
        "        with create_tempdir():\n",
        "\n",
        "            # These system calls are needed when cleaning up tempdir.\n",
        "            import os\n",
        "            import shutil\n",
        "            rmtree = shutil.rmtree\n",
        "            rmdir = os.rmdir\n",
        "            chdir = os.chdir\n",
        "\n",
        "            # Disable functionalities that can make destructive changes to the test.\n",
        "            reliability_guard()\n",
        "\n",
        "            # Construct the check program and run it.\n",
        "            check_program = (\n",
        "                problem[\"prompt\"] + completion + \"\\n\" +\n",
        "                problem[\"test\"] + \"\\n\" +\n",
        "                f\"check({problem['entry_point']})\"\n",
        "            )\n",
        "\n",
        "            try:\n",
        "                exec_globals = {}\n",
        "                with swallow_io():\n",
        "                    with time_limit(timeout):\n",
        "# WARNING\n",
        "# This program exists to execute untrusted model-generated code. Although\n",
        "# it is highly unlikely that model-generated code will do something overtly\n",
        "# malicious in response to this test suite, model-generated code may act\n",
        "# destructively due to a lack of model capability or alignment.\n",
        "# Users are strongly encouraged to sandbox this evaluation suite so that it\n",
        "# does not perform destructive actions on their host or network. For more\n",
        "# information on how OpenAI sandboxes its code, see the accompanying paper.\n",
        "# Once you have read this disclaimer and taken appropriate precautions,\n",
        "# uncomment the following line and proceed at your own risk:\n",
        "                        exec(check_program, exec_globals)\n",
        "                result.append(\"passed\")\n",
        "            except TimeoutException:\n",
        "                result.append(\"timed out\")\n",
        "            except BaseException as e:\n",
        "                result.append(f\"failed: {e}\")\n",
        "\n",
        "            # Needed for cleaning up.\n",
        "            shutil.rmtree = rmtree\n",
        "            os.rmdir = rmdir\n",
        "            os.chdir = chdir\n",
        "\n",
        "    manager = multiprocessing.Manager()\n",
        "    result = manager.list()\n",
        "\n",
        "    p = multiprocessing.Process(target=unsafe_execute)\n",
        "    p.start()\n",
        "    p.join(timeout=timeout + 1)\n",
        "    if p.is_alive():\n",
        "        p.kill()\n",
        "\n",
        "    if not result:\n",
        "        result.append(\"timed out\")\n",
        "\n",
        "    return dict(\n",
        "        task_id=problem[\"task_id\"],\n",
        "        passed=result[0] == \"passed\",\n",
        "        result=result[0],\n",
        "        completion_id=completion_id,\n",
        "    )\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def time_limit(seconds: float):\n",
        "    def signal_handler(signum, frame):\n",
        "        raise TimeoutException(\"Timed out!\")\n",
        "    signal.setitimer(signal.ITIMER_REAL, seconds)\n",
        "    signal.signal(signal.SIGALRM, signal_handler)\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        signal.setitimer(signal.ITIMER_REAL, 0)\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def swallow_io():\n",
        "    stream = WriteOnlyStringIO()\n",
        "    with contextlib.redirect_stdout(stream):\n",
        "        with contextlib.redirect_stderr(stream):\n",
        "            with redirect_stdin(stream):\n",
        "                yield\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def create_tempdir():\n",
        "    with tempfile.TemporaryDirectory() as dirname:\n",
        "        with chdir(dirname):\n",
        "            yield dirname\n",
        "\n",
        "\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class WriteOnlyStringIO(io.StringIO):\n",
        "    \"\"\" StringIO that throws an exception when it's read from \"\"\"\n",
        "\n",
        "    def read(self, *args, **kwargs):\n",
        "        raise IOError\n",
        "\n",
        "    def readline(self, *args, **kwargs):\n",
        "        raise IOError\n",
        "\n",
        "    def readlines(self, *args, **kwargs):\n",
        "        raise IOError\n",
        "\n",
        "    def readable(self, *args, **kwargs):\n",
        "        \"\"\" Returns True if the IO object can be read. \"\"\"\n",
        "        return False\n",
        "\n",
        "\n",
        "class redirect_stdin(contextlib._RedirectStream):  # type: ignore\n",
        "    _stream = 'stdin'\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def chdir(root):\n",
        "    if root == \".\":\n",
        "        yield\n",
        "        return\n",
        "    cwd = os.getcwd()\n",
        "    os.chdir(root)\n",
        "    try:\n",
        "        yield\n",
        "    except BaseException as exc:\n",
        "        raise exc\n",
        "    finally:\n",
        "        os.chdir(cwd)\n",
        "\n",
        "\n",
        "def reliability_guard(maximum_memory_bytes: Optional[int] = None):\n",
        "    \"\"\"\n",
        "    This disables various destructive functions and prevents the generated code\n",
        "    from interfering with the test (e.g. fork bomb, killing other processes,\n",
        "    removing filesystem files, etc.)\n",
        "\n",
        "    WARNING\n",
        "    This function is NOT a security sandbox. Untrusted code, including, model-\n",
        "    generated code, should not be blindly executed outside of one. See the\n",
        "    Codex paper for more information about OpenAI's code sandbox, and proceed\n",
        "    with caution.\n",
        "    \"\"\"\n",
        "\n",
        "    if maximum_memory_bytes is not None:\n",
        "        import resource\n",
        "        resource.setrlimit(resource.RLIMIT_AS, (maximum_memory_bytes, maximum_memory_bytes))\n",
        "        resource.setrlimit(resource.RLIMIT_DATA, (maximum_memory_bytes, maximum_memory_bytes))\n",
        "        if not platform.uname().system == 'Darwin':\n",
        "            resource.setrlimit(resource.RLIMIT_STACK, (maximum_memory_bytes, maximum_memory_bytes))\n",
        "\n",
        "    faulthandler.disable()\n",
        "\n",
        "    import builtins\n",
        "    builtins.exit = None\n",
        "    builtins.quit = None\n",
        "\n",
        "    import os\n",
        "    os.environ['OMP_NUM_THREADS'] = '1'\n",
        "\n",
        "    os.kill = None\n",
        "    os.system = None\n",
        "    os.putenv = None\n",
        "    os.remove = None\n",
        "    os.removedirs = None\n",
        "    os.rmdir = None\n",
        "    os.fchdir = None\n",
        "    os.setuid = None\n",
        "    os.fork = None\n",
        "    os.forkpty = None\n",
        "    os.killpg = None\n",
        "    os.rename = None\n",
        "    os.renames = None\n",
        "    os.truncate = None\n",
        "    os.replace = None\n",
        "    os.unlink = None\n",
        "    os.fchmod = None\n",
        "    os.fchown = None\n",
        "    os.chmod = None\n",
        "    os.chown = None\n",
        "    os.chroot = None\n",
        "    os.fchdir = None\n",
        "    os.lchflags = None\n",
        "    os.lchmod = None\n",
        "    os.lchown = None\n",
        "    os.getcwd = None\n",
        "    os.chdir = None\n",
        "\n",
        "    import shutil\n",
        "    shutil.rmtree = None\n",
        "    shutil.move = None\n",
        "    shutil.chown = None\n",
        "\n",
        "    import subprocess\n",
        "    subprocess.Popen = None  # type: ignore\n",
        "\n",
        "    __builtins__['help'] = None\n",
        "\n",
        "    import sys\n",
        "    sys.modules['ipdb'] = None\n",
        "    sys.modules['joblib'] = None\n",
        "    sys.modules['resource'] = None\n",
        "    sys.modules['psutil'] = None\n",
        "    sys.modules['tkinter'] = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHVcnE7L__AW",
        "outputId": "732333c5-3342-4a24-e80c-f095bfa24557"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/human-eval/human_eval/execution.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/human-eval/human_eval/execution.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX0B1EfmADlz",
        "outputId": "a5343807-a1f5-46ee-8be4-68986fb459af"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from typing import Optional, Callable, Dict\n",
            "import ast\n",
            "import contextlib\n",
            "import faulthandler\n",
            "import io\n",
            "import os\n",
            "import multiprocessing\n",
            "import platform\n",
            "import signal\n",
            "import tempfile\n",
            "\n",
            "\n",
            "def check_correctness(problem: Dict, completion: str, timeout: float,\n",
            "                      completion_id: Optional[int] = None) -> Dict:\n",
            "    \"\"\"\n",
            "    Evaluates the functional correctness of a completion by running the test\n",
            "    suite provided in the problem. \n",
            "\n",
            "    :param completion_id: an optional completion ID so we can match\n",
            "        the results later even if execution finishes asynchronously.\n",
            "    \"\"\"\n",
            "\n",
            "    def unsafe_execute():\n",
            "\n",
            "        with create_tempdir():\n",
            "\n",
            "            # These system calls are needed when cleaning up tempdir.\n",
            "            import os\n",
            "            import shutil\n",
            "            rmtree = shutil.rmtree\n",
            "            rmdir = os.rmdir\n",
            "            chdir = os.chdir\n",
            "\n",
            "            # Disable functionalities that can make destructive changes to the test.\n",
            "            reliability_guard()\n",
            "\n",
            "            # Construct the check program and run it.\n",
            "            check_program = (\n",
            "                problem[\"prompt\"] + completion + \"\\n\" +\n",
            "                problem[\"test\"] + \"\\n\" +\n",
            "                f\"check({problem['entry_point']})\"\n",
            "            )\n",
            "\n",
            "            try:\n",
            "                exec_globals = {}\n",
            "                with swallow_io():\n",
            "                    with time_limit(timeout):\n",
            "# WARNING\n",
            "# This program exists to execute untrusted model-generated code. Although\n",
            "# it is highly unlikely that model-generated code will do something overtly\n",
            "# malicious in response to this test suite, model-generated code may act\n",
            "# destructively due to a lack of model capability or alignment.\n",
            "# Users are strongly encouraged to sandbox this evaluation suite so that it \n",
            "# does not perform destructive actions on their host or network. For more \n",
            "# information on how OpenAI sandboxes its code, see the accompanying paper.\n",
            "# Once you have read this disclaimer and taken appropriate precautions, \n",
            "# uncomment the following line and proceed at your own risk:\n",
            "                        exec(check_program, exec_globals)\n",
            "                result.append(\"passed\")\n",
            "            except TimeoutException:\n",
            "                result.append(\"timed out\")\n",
            "            except BaseException as e:\n",
            "                result.append(f\"failed: {e}\")\n",
            "\n",
            "            # Needed for cleaning up.\n",
            "            shutil.rmtree = rmtree\n",
            "            os.rmdir = rmdir\n",
            "            os.chdir = chdir\n",
            "\n",
            "    manager = multiprocessing.Manager()\n",
            "    result = manager.list()\n",
            "\n",
            "    p = multiprocessing.Process(target=unsafe_execute)\n",
            "    p.start()\n",
            "    p.join(timeout=timeout + 1)\n",
            "    if p.is_alive():\n",
            "        p.kill()\n",
            "\n",
            "    if not result:\n",
            "        result.append(\"timed out\")\n",
            "\n",
            "    return dict(\n",
            "        task_id=problem[\"task_id\"],\n",
            "        passed=result[0] == \"passed\",\n",
            "        result=result[0],\n",
            "        completion_id=completion_id,\n",
            "    )\n",
            "\n",
            "\n",
            "@contextlib.contextmanager\n",
            "def time_limit(seconds: float):\n",
            "    def signal_handler(signum, frame):\n",
            "        raise TimeoutException(\"Timed out!\")\n",
            "    signal.setitimer(signal.ITIMER_REAL, seconds)\n",
            "    signal.signal(signal.SIGALRM, signal_handler)\n",
            "    try:\n",
            "        yield\n",
            "    finally:\n",
            "        signal.setitimer(signal.ITIMER_REAL, 0)\n",
            "\n",
            "\n",
            "@contextlib.contextmanager\n",
            "def swallow_io():\n",
            "    stream = WriteOnlyStringIO()\n",
            "    with contextlib.redirect_stdout(stream):\n",
            "        with contextlib.redirect_stderr(stream):\n",
            "            with redirect_stdin(stream):\n",
            "                yield\n",
            "\n",
            "\n",
            "@contextlib.contextmanager\n",
            "def create_tempdir():\n",
            "    with tempfile.TemporaryDirectory() as dirname:\n",
            "        with chdir(dirname):\n",
            "            yield dirname\n",
            "\n",
            "\n",
            "class TimeoutException(Exception):\n",
            "    pass\n",
            "\n",
            "\n",
            "class WriteOnlyStringIO(io.StringIO):\n",
            "    \"\"\" StringIO that throws an exception when it's read from \"\"\"\n",
            "\n",
            "    def read(self, *args, **kwargs):\n",
            "        raise IOError\n",
            "\n",
            "    def readline(self, *args, **kwargs):\n",
            "        raise IOError\n",
            "\n",
            "    def readlines(self, *args, **kwargs):\n",
            "        raise IOError\n",
            "\n",
            "    def readable(self, *args, **kwargs):\n",
            "        \"\"\" Returns True if the IO object can be read. \"\"\"\n",
            "        return False\n",
            "\n",
            "\n",
            "class redirect_stdin(contextlib._RedirectStream):  # type: ignore\n",
            "    _stream = 'stdin'\n",
            "\n",
            "\n",
            "@contextlib.contextmanager\n",
            "def chdir(root):\n",
            "    if root == \".\":\n",
            "        yield\n",
            "        return\n",
            "    cwd = os.getcwd()\n",
            "    os.chdir(root)\n",
            "    try:\n",
            "        yield\n",
            "    except BaseException as exc:\n",
            "        raise exc\n",
            "    finally:\n",
            "        os.chdir(cwd)\n",
            "\n",
            "\n",
            "def reliability_guard(maximum_memory_bytes: Optional[int] = None):\n",
            "    \"\"\"\n",
            "    This disables various destructive functions and prevents the generated code\n",
            "    from interfering with the test (e.g. fork bomb, killing other processes,\n",
            "    removing filesystem files, etc.)\n",
            "\n",
            "    WARNING\n",
            "    This function is NOT a security sandbox. Untrusted code, including, model-\n",
            "    generated code, should not be blindly executed outside of one. See the \n",
            "    Codex paper for more information about OpenAI's code sandbox, and proceed\n",
            "    with caution.\n",
            "    \"\"\"\n",
            "\n",
            "    if maximum_memory_bytes is not None:\n",
            "        import resource\n",
            "        resource.setrlimit(resource.RLIMIT_AS, (maximum_memory_bytes, maximum_memory_bytes))\n",
            "        resource.setrlimit(resource.RLIMIT_DATA, (maximum_memory_bytes, maximum_memory_bytes))\n",
            "        if not platform.uname().system == 'Darwin':\n",
            "            resource.setrlimit(resource.RLIMIT_STACK, (maximum_memory_bytes, maximum_memory_bytes))\n",
            "\n",
            "    faulthandler.disable()\n",
            "\n",
            "    import builtins\n",
            "    builtins.exit = None\n",
            "    builtins.quit = None\n",
            "\n",
            "    import os\n",
            "    os.environ['OMP_NUM_THREADS'] = '1'\n",
            "\n",
            "    os.kill = None\n",
            "    os.system = None\n",
            "    os.putenv = None\n",
            "    os.remove = None\n",
            "    os.removedirs = None\n",
            "    os.rmdir = None\n",
            "    os.fchdir = None\n",
            "    os.setuid = None\n",
            "    os.fork = None\n",
            "    os.forkpty = None\n",
            "    os.killpg = None\n",
            "    os.rename = None\n",
            "    os.renames = None\n",
            "    os.truncate = None\n",
            "    os.replace = None\n",
            "    os.unlink = None\n",
            "    os.fchmod = None\n",
            "    os.fchown = None\n",
            "    os.chmod = None\n",
            "    os.chown = None\n",
            "    os.chroot = None\n",
            "    os.fchdir = None\n",
            "    os.lchflags = None\n",
            "    os.lchmod = None\n",
            "    os.lchown = None\n",
            "    os.getcwd = None\n",
            "    os.chdir = None\n",
            "\n",
            "    import shutil\n",
            "    shutil.rmtree = None\n",
            "    shutil.move = None\n",
            "    shutil.chown = None\n",
            "\n",
            "    import subprocess\n",
            "    subprocess.Popen = None  # type: ignore\n",
            "\n",
            "    __builtins__['help'] = None\n",
            "\n",
            "    import sys\n",
            "    sys.modules['ipdb'] = None\n",
            "    sys.modules['joblib'] = None\n",
            "    sys.modules['resource'] = None\n",
            "    sys.modules['psutil'] = None\n",
            "    sys.modules['tkinter'] = None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!evaluate_functional_correctness human-eval/data/example_samples.jsonl --problem_file=human-eval/data/example_problem.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRKdTgef-z94",
        "outputId": "b5805ac3-b707-4396-d69f-819d1dc234b4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading samples...\n",
            "\r0it [00:00, ?it/s]\r6it [00:00, 516.27it/s]\n",
            "Running test suites...\n",
            "100% 6/6 [00:03<00:00,  1.97it/s]\n",
            "Writing results to human-eval/data/example_samples.jsonl_results.jsonl...\n",
            "100% 6/6 [00:00<00:00, 9784.53it/s]\n",
            "{'pass@1': 0.4999999999999999}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/parsakzr/ytu-bitirme/main/humaneval_Salesforce_codegen-350M-mono_predictions.jsonl?token=GHSAT0AAAAAAB7SHOECYN2352TKMN5PRLJUZMYUN2Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JNRiQNiAlBZ",
        "outputId": "c1711b9e-f614-4a91-dabe-543ff364edad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-05 23:49:04--  https://raw.githubusercontent.com/parsakzr/ytu-bitirme/main/humaneval_Salesforce_codegen-350M-mono_predictions.jsonl?token=GHSAT0AAAAAAB7SHOECYN2352TKMN5PRLJUZMYUN2Q\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43946 (43K) [text/plain]\n",
            "Saving to: ‘humaneval_Salesforce_codegen-350M-mono_predictions.jsonl?token=GHSAT0AAAAAAB7SHOECYN2352TKMN5PRLJUZMYUN2Q’\n",
            "\n",
            "\r          humaneval   0%[                    ]       0  --.-KB/s               \rhumaneval_Salesforc 100%[===================>]  42.92K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-01-05 23:49:05 (4.14 MB/s) - ‘humaneval_Salesforce_codegen-350M-mono_predictions.jsonl?token=GHSAT0AAAAAAB7SHOECYN2352TKMN5PRLJUZMYUN2Q’ saved [43946/43946]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv humaneval_Salesforce_codegen-350M-mono_predictions.jsonl?token=GHSAT0AAAAAAB7SHOECYN2352TKMN5PRLJUZMYUN2Q humaneval_Salesforce_codegen-350M-mono_predictions.jsonl"
      ],
      "metadata": {
        "id": "c3-xYuvKB0DT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!evaluate_functional_correctness humaneval_Salesforce_codegen-350M-mono_predictions.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIA-OlzaCHwA",
        "outputId": "95e3720e-a7f1-4a5c-8df3-b3e6d4daffb4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading samples...\n",
            "\r0it [00:00, ?it/s]\r164it [00:00, 24423.59it/s]\n",
            "Running test suites...\n",
            "100% 164/164 [00:03<00:00, 48.66it/s]\n",
            "Writing results to humaneval_Salesforce_codegen-350M-mono_predictions.jsonl_results.jsonl...\n",
            "100% 164/164 [00:00<00:00, 58278.90it/s]\n",
            "{'pass@1': 0.1402439024390244}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CFTM_l9CQLT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}